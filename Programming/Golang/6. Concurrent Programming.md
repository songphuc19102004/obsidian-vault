# Function Literals
![[function-literals-definition.png]]

### Anonymous Function
![[function-literals-anonymous-func.png]]

### As Function Parameter
![[functional-literal-as-func-param.png]]
### Closure
#### Example 1
![[function-literal-closure.png]]
![[function-literal-closure2.png]]

#### Example 2
```go
package main

import "fmt"

func intSeq() func() int {
    i := 0
    return func() int {
        i++
        return i
    }
}

func main() {

    nextInt := intSeq()

    fmt.Println(nextInt())
    fmt.Println(nextInt())
    fmt.Println(nextInt())

    newInts := intSeq()
    fmt.Println(newInts())
}
```
- ***intSeq()*** actually works like a ***function factory***, means that it creates a function that return an int, and add an ***extra independent variable state***(in this case **i***)
- ***nextInt*** is of type func() int and that func is created by ***intSeq()***. Every time it calls the function ***nextInt*** is holding, it increase i and also return i.

### Type Alias
![[function-literal-type-alias.png]]
- When we work with function literals and closures, the parameters can get quite verbose.
=> We can create a ***Type Alias***.

### Recap
![[function-literal-recap.png]]

# Defer
> To delay, postpone.
![[defer-definition.png]]

### How it works
![[defer-how-it-works.png]]
- deferred functions will be placed on a stack. 
![[defer-stack.png]]

### Example
![[defer-example.png]]
- In Go, the **idiomatic** way to ensure a file (or any resource) is **always** closed is to place the `defer file.Close()` statement immediately after successfully opening the file.

# Concurrency
![[concurrency-definition.png]]

### Threaded Execution
![[concurrency-threaded-execution.png]]
- Here we have a CPU core, and it executes code on the Main Thread. We then have 4 other Cores that can execute code, and the Main Thread can branch off into these Cores. Those Cores can do their own thing, and then join their data back onto the Main Thread. So when we get the data back, we're joining on the Main Thread. Generally, we want to wait for all these jobs (process by a Core) to finish. The Main Thread will just pause and wait for all the result to finish and the execution of the Main Thread would continue.
=> The main takeaway for any kind of concurrent programming is we do have to wait on our main Thread, before we can continue on with the program. 

### Asynchronous Execution
![[concurrent-programming-asynchronous-execution.png]]
- Looking at the CPU Utilization, we can see the CPU is being used the entire time. It just being spread out across jobs.
=> Just like with the threaded execution, at the very end, we would want to collect all the results, and then continue on with our work.

### Details
![[concurrent-programming-details.png]]
### Recap
![[concurrent-programming-recap.png.png]]