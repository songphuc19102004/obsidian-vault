# Function Literals
![[function-literals-definition.png]]

### Anonymous Function
![[function-literals-anonymous-func.png]]

### As Function Parameter
![[functional-literal-as-func-param.png]]
### Closure
#### Example 1
![[function-literal-closure.png]]
![[function-literal-closure2.png]]

#### Example 2
```go
package main

import "fmt"

func intSeq() func() int {
    i := 0
    return func() int {
        i++
        return i
    }
}

func main() {

    nextInt := intSeq()

    fmt.Println(nextInt())
    fmt.Println(nextInt())
    fmt.Println(nextInt())

    newInts := intSeq()
    fmt.Println(newInts())
}

// ---------------------------------------------------------------------------
// go run closures.go
// 1
// 2
// 3
// 1
// ---------------------------------------------------------------------------
```


- ***intSeq()*** actually works like a ***function factory***, means that it creates a function that return an int, and add an ***extra independent variable state***(in this case **i***)
- ***nextInt*** is of type func() int and that func is created by ***intSeq()***. Every time it calls the function ***nextInt*** is holding, it increase i and also return i.

### Type Alias
![[function-literal-type-alias.png]]
- When we work with function literals and closures, the parameters can get quite verbose.
=> We can create a ***Type Alias***.

### Recap
![[function-literal-recap.png]]

# Defer
> To delay, postpone.
![[defer-definition.png]]

### How it works
![[defer-how-it-works.png]]
- deferred functions will be placed on a stack. 
![[defer-stack.png]]

### Example
![[defer-example.png]]
- In Go, the **idiomatic** way to ensure a file (or any resource) is **always** closed is to place the `defer file.Close()` statement immediately after successfully opening the file.

# Concurrency
![[concurrency-definition.png]]

### Threaded Execution
![[concurrency-threaded-execution.png]]
- Here we have a CPU core, and it executes code on the Main Thread. We then have 4 other Cores that can execute code, and the Main Thread can branch off into these Cores. Those Cores can do their own thing, and then join their data back onto the Main Thread. So when we get the data back, we're joining on the Main Thread. Generally, we want to wait for all these jobs (process by a Core) to finish. The Main Thread will just pause and wait for all the result to finish and the execution of the Main Thread would continue.
=> The main takeaway for any kind of concurrent programming is we do have to wait on our main Thread, before we can continue on with the program. 

### Asynchronous Execution
![[concurrent-programming-asynchronous-execution.png]]
- Looking at the CPU Utilization, we can see the CPU is being used the entire time. It just being spread out across jobs.
=> Just like with the threaded execution, at the very end, we would want to collect all the results, and then continue on with our work.

### Details
![[concurrent-programming-details.png]]
### Recap
![[concurrent-programming-recap.png.png]]

# Goroutines
![[goroutines-definition.png]]
### Example - Basic
![[goroutines-example-basic.png]]

### Example - Closures
![[goroutines-example-closures.png]]
- An important takeaway with goroutines is when we launch a goroutine using ***go***, what happen is the ***Main Thread*** just keeps on going and our ***goroutines*** (in this case: ***wait()***), that is doing its own thing in the background, and so we have ***2 Threads of execution*** going at the same time.

### Recap
![[goroutines-recap.png]]

# Channels
![[channels-definition.png]]
### Visual
![[channels-visual.png]]

### Multiple Receive Ends
![[channels-multiple-receive-ends.png]]
- We can see one channel with ***multiple reading*** ends and a ***single writing*** end. This architecture is useful if our data takes a long time to process.
- For example: we can have a web server with data coming in, and then we can split the work up into three different goroutines by using a channel

### Creation & Usage
![[channels-creation-usage.png]]
- make(chan int) creates a channel that can communicate using integers only.
- To send data to a channel, we use less than then dash (<-)
	- In the example, we are sending 1, 2, and 3 to the channel
	- Each one of these sends to the channel is occurring within a goroutine, because the channel is ***unbuffered***. This means for every message sent in, we need to receive a message out. 

### Details
![[channels-details.png]]
- Even though goroutines are nondeterministic and can place data in any order within the channels, once the data is actually in the channel, it will always come out at the same order that it was placed.

### Buffered Channel
![[channels-buffered-channel.png]]
- make(chan int, 2) creates a channel with a buffer size of 2. Buffer size of 2 indicates that we can place two pieces of data in the channel and we won't block.

### Goroutines: Unidirectional Channels
![[channels-unidirectional-channel.png]]
- A unidirectional channel is one where data only flows in one direction.

### Goroutines: Control Channel
![[channels-control-channel.png]]
- With Control Channel, each goroutine creates its own channel to communicate back with the main thread.
- We still have a single channel sending data to the goroutines, and we have a separated channel now, sending data back from the goroutines. 
=> There is a single channel from the Main Thread to communicate with the goroutines, and there is a single channel for the goroutines to communicate with the Main Thread -> Data and Messages aren't getting mixed up.

### Channel Selection
![[channels-selection.png]]
- **select*** is kinda like ***switch case***

### Timeouts
![[channels-timeouts.png]]
- time.After is going to create a channel and return some data after some time specified.
- if one or two take longer than 300ms, to return data, then time.After() will return some data and print out "timed out" and break out of the loop.
=> Useful when we are working with data that goes stale after a certain amount of time.

### Recap
![[channels-recap.png]]

# Synchronization
![[synchronization-definition.png]]

### Mutex
![[synchronization-mutex.png]]

#### Visual
![[synchronization-mutex-visual.png]]
- We have a shared data and two goroutines A and B.
- A has exclusive access to the data until it's unlocked.
- Once goroutine A unlocks the data, it becomes shared again.
- The dashing line is goroutine B is waiting until it can acquire a Lock.

#### Example
![[synchronization-mutex-example.png]]

### Deferred Unlock
![[synchronization-deferred-unlock.png]]
- When working with Mutex, always remember to ***Unlock***, else it will freeze to program.

### Wait Groups
![[synchronization-wait-groups.png]]

#### Example
![[synchronization-wait-groups-example.png]]

### Recap
![[synchronization-recap.png]]

# Concurrency Patterns
![[concurrency-pattern-about.png]]

### Pipelines
![[concurrency-pattern-pipeline.png]]
- Each pipeline has to have at least 1 input channel and 1 output channel.

#### Visual
![[concurrency-pattern-pipeline-visual.png]]
- Each one of these squares represents a stage in the pipeline and it can operating as a goroutine.
- Each one of these stages has 2 channels (in and out).

### Patterns
#### Fan-in
![[concurrency-pattern-fanin.png]]
- Example: serializing requests to purchase an item: multiple people trying to purchase one item, we can **fan in*** all those requests into a single output channel. That way when the stock runs out, nobody can purchase the item.

#### Visual
![[concurrency-pattern-fanin-visual.png]]

#### Close / Cancellation
![[concurrency-pattern-close-cancellation.png]]

#### Visual
![[concurrency-pattern-close-cancellation-visual.png]]
- Fan-in pattern with the ability to close the channels.

#### Request Quit
![[concurrency-pattern-request-quit.png]]

#### Visual
![[concurrency-pattern-request-quit-visual.png]]
- Send 4 signals to quit all 4 goroutines.

#### Context
![[concurrency-pattern-context.png]]

#### Visual
![[concurrency-pattern-context-visual.png]]
- A bit similar to quit channel.
- All the second stage needs to do is call the abort operation that's going to propagate automatically. -> Everything will get cancelled except the second stage.

#### Generator
![[concurrency-pattern-generator.png]]
- Generators are great if we have something that we know is going to take a lot of calculations. However, we don't want to calculate all of them at once.
- Example: search results: 10k results and we only want to display 10 at a time. We can make a generator with a channel of size 10, then we only get 10 results at a time.
#### Visual
![[concurrency-pattern-generator-visual.png]]

### Recap
![[concurrency-pattern-recap.png]]